{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Guía 7 - Pronósticos de demanda diaria con LSTM usando Keras y TensorFlow\n",
    "\n",
    "## Pronósticos a partir de la serie temporal de la demanda diaria \n",
    "\n",
    "La propuesta es dar pronósticos de la demanda diaria de energía eléctrica a partir de sus valores registrados en días anteriores. Estos pronósticos lo obtendremos a partir del entrenamiento de redes neuronales (Neural Networks, NN) usando celdas del tipo *Long-Short-Time-Memory* (LSTM) y de otras configuraciones.\n",
    "\n",
    "Continuaremos con nuestro ejemplo tomando la base de datos de demanda diaria de energía eléctrica publicados por CAMMESA [descargar](https://cammesaweb.cammesa.com/2024/12/20/covid-19-comportamiento-de-la-demanda-de-energia-electrica-en-el-mem/#).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Inicio de la programación para el análisis y pronóstico de la series temporales\n",
    "\n",
    "Comenzamos importando las bibliotecas necesarias y confirmamos la versión de TensorFlow (TF) disponible en la instalación. Esto nos puede ayudar a interpretar algunas diferencias en el comportamiento de las funciones de TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(99)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Carga del conjunto de datos para su análisis\n",
    "\n",
    "Cargamos los datos de demanda diaria desde [aquí](https://cammesaweb.cammesa.com/2024/12/20/covid-19-comportamiento-de-la-demanda-de-energia-electrica-en-el-mem/#). `DEMANDA TOTAL` es la serie que queremos predecir (target). Esperamos que sus valores históricos nos provean información para su pronóstico.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "dataFrame = pd.read_excel('Data/Base Demanda Diaria 2017 2024.xlsx', sheet_name='Datos Región', skiprows=4)  \n",
    "dtotal = dataFrame.pop('DEMANDA TOTAL').to_numpy().reshape(-1,1)\n",
    "# TF usa por default float32\n",
    "dtotal = np.float32(dtotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Llevamos los datos al tipo `float32` ya que TF trabaja con esa precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Separación de los conjuntos de datos de entrenamiento y prueba\n",
    "\n",
    "Como es habitual, separamos el conjunto de datos en entrenamiento y prueba. Para las series temporales se deja una porción del final como datos de prueba. Lo más importante es asegurar que el modelo se evalúa con datos futuros. Para más detalles, en particular sobre la aplicación de validación cruzada a series temporales, se puede consultar  [SciKit-Learn: Cross validation of time series data](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-of-time-series-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset splitting\n",
    "SPLIT = 0.85\n",
    "dtotal_len = len(dtotal)\n",
    "train_set = dtotal[:int(SPLIT * dtotal_len)]\n",
    "test_set = dtotal[int(SPLIT * dtotal_len):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Normalización de los datos\n",
    "\n",
    "Es fundamental (y no debemos olvidarnos de) comenzar por escalar los datos para ser procesados por la NN. Sin embargo, no es necesario asumir que la distribución de datos es estacionaria como tampoco es necesario corregir por tendencias o estacionalidad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_set)\n",
    "train_std = np.std(train_set)\n",
    "print('Media: {:.0f}MW'.format(train_mean))\n",
    "print('Desviación estándard: {:.0f}MW'.format(train_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = (train_set - train_mean) / train_std\n",
    "test_scaled = (test_set - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Ventanas de datos\n",
    "\n",
    "Lo importante es particionar la serie temporal en lotes *operables* por las sucesivas capas de NN. Es importante notar que dentro de cada lote se conserva el orden temporal...\n",
    "\n",
    "Ilustramos el proceso de *windowing* asumiendo ventanas sucesivas de 7 datos. Así, cada lote se compone de 6 datos de entrada y un dato (el último) para las etiquetas. En este caso no se deja *offset* para comenzar con las etiquetas ni separaciones entre ventanas (*stride*).\n",
    "\n",
    "![Ilustración de *windowing*](Figs/windowing.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single step dataset preparation\n",
    "# The input of LSTM layer has a shape of (num_timesteps, num_features)\n",
    "def singleStepSampler(df, window):\n",
    "    xRes = []\n",
    "    yRes = []\n",
    "    for i in range(0, len(df) - window):\n",
    "        res = []\n",
    "        for j in range(0, window):\n",
    "            res.append(df[i+j,0])\n",
    "        xRes.append(res)\n",
    "        yRes.append(df[i + window,0])\n",
    "    return np.array(xRes), np.array(yRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Aplicamos las ventanas a los datos de prueba y entrenamiento. Dentro de cada ventana se arman lotes de datos de tamaño `BATCH_SIZE`. Así, `X` guardará la información de los días previos de la demanda e `y` almacenará la predicción para el día siguiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un ciclo completo de 4 semanas\n",
    "# igual cantidad de instancias de lunes que de domingos (4)\n",
    "BATCH_SIZE = 28 \n",
    "\n",
    "(X_train, y_train) = singleStepSampler(train_scaled, BATCH_SIZE)\n",
    "(X_test, y_test) = singleStepSampler(test_scaled, BATCH_SIZE)\n",
    "\n",
    "X_train = X_train[...,np.newaxis]\n",
    "y_train = y_train[...,np.newaxis]\n",
    "X_test = X_test[...,np.newaxis]\n",
    "y_test = y_test[...,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Es interesante comparar ahora las dimensiones de los difrentes `Arrays` involucrados. Ciertamente, predecimos `DEMANDA TOTAL` en el paso siguiente... por eso también existen como atributos en el paso de tiempo anterior dentro del conjunto de datos de entrada a la NN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Datos de entrenamiento original de tamaño: ', train_scaled.shape)\n",
    "\n",
    "print('Lotes de entrenamiento de tamaño: ', X_train.shape)\n",
    "print('Lotes de targets de enetrenamiento de tamaño: ', y_train.shape)\n",
    "print('Vemos que el `Array` se transformó en {} lotes cada uno con {} registros o instancias'.format(X_train.shape[0], BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Además, confirmamos la cantidad de columnas del target y que esas columnas también están presentes en los datos de entrada... (1 columna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Vamos a realizar un gráfico para mostrar que cada lote se va trasldando en 1 paso de tiempo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(BATCH_SIZE), train_scaled[0:BATCH_SIZE,0], linestyle='--', marker='.')\n",
    "# Plot del segundo lote de datos\n",
    "# Debe verse un paso de tiempo corrido\n",
    "plt.scatter(np.arange(1, BATCH_SIZE+1), X_train[1, :,0], c='r', marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Modelo multipaso, de secuencia a vector\n",
    "\n",
    "Vamos a crear un modelo con NN que nos permitirá pronosticar el valor de `DEMANDA TOTAL` en el paso de tiempo siguiente a partir de una secuencia de datos de longitud `BATCH_SIZE`. No le vamos a decir cuántos lotes hay pero sí la dimensión de cada uno. \n",
    "\n",
    "### Usando la Sequential API para definir el modelo\n",
    "\n",
    "Es una método para definir un modelo de NN que enfatiza el flujo de información secuencial desde la primera capa hacia la útlima.\n",
    "\n",
    "Introducimos una primer capa con celdas LSTM. La capa `Dropout` no tiene parámetros o pesos ajustables. Solo permite deshabilitar aleatoriamente una fracción de las celdas. Esta técnica de tipo *ensamble* mejora la estimación final. La útlima capa es de activación lineal para dar valores continuos. Tiene 1 unidad ya que buscamos predecir los valores de `DEMANDA TOTAL` (1 columna). Es interesante notar que así, de cada lote, dará un único valor de `DEMANDA TOTAL`. Es una sequence-to-vector (multiple-input-time-step)... Esto se logra por cómo se define la NN... Sin embargo, si en la definición de la celda LSTM agregamos `return_sequence=True` entonces tendríamos una sequence-to-sequence (ver ejercicios).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definig LSTM model\n",
    "multivariate_lstm = keras.Sequential()\n",
    "multivariate_lstm.add(keras.layers.Input((X_train.shape[1], 1)))\n",
    "multivariate_lstm.add(keras.layers.LSTM(10))\n",
    "multivariate_lstm.add(keras.layers.Dropout(0.2))\n",
    "multivariate_lstm.add(keras.layers.Dense(1, activation='linear'))\n",
    "#multivariate_lstm.add(keras.layers.LSTM(200, return_sequences=True))\n",
    "#multivariate_lstm.add(keras.layers.Dropout(0.2))\n",
    "#multivariate_lstm.add(keras.layers.LSTM(20))\n",
    "#multivariate_lstm.add(keras.layers.Dropout(0.2))\n",
    "#multivariate_lstm.add(keras.layers.Dense(units=1))\n",
    "multivariate_lstm.compile(loss = 'MeanSquaredError', metrics=['MAE'], optimizer='Adam')\n",
    "multivariate_lstm.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "El método `.summary()`nos muestra cómo fluirá la información entre las capas de NN y cuántos parámetros se deberán ajustar en cada una. Otra alternativa para representar la configuración de la NN es usar `tf.keras.utils.plot_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(multivariate_lstm, to_file='Figs/model.png', show_shapes=True,\n",
    "                          show_dtype=True, show_layer_names=True, rankdir='TB',\n",
    "                          expand_nested=True, dpi=200, show_layer_activations=True,\n",
    "                          show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Vamos a profundizar el análisis sobre los pesos. Imprimimos sus tamaños y leeremos los pesos asignados inicialmente al *bias* tomando algunas muestras separadas de a 2 registros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_lstm.layers[0].name\n",
    "w1, w2, bias = multivariate_lstm.layers[0].get_weights()\n",
    "# print(multivariate_lstm.layers[0].trainable_weights)\n",
    "print(w1.shape)\n",
    "print(w2.shape)\n",
    "print(bias.shape)\n",
    "# Pesos iniciales aleatorios y bias en 0\n",
    "bias[::2] # mostramos de 2 en 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Interpretación de las dimensiones de los pesos y bias\n",
    "\n",
    "Tanto la representación de la celda LSTM \n",
    "\n",
    "![Celda LSTM](Figs/LSTM_weights.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "como la forma compacta de sus ecuaciones ([Wiki-LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory)) nos muestran la existencia de 4 pesos por estado $x_t$ , 4 pesos por estado oculto $h_{t-1}$ , y 4 valores de bias. Para el ejemplo con 200 unidades resulta:\n",
    "\n",
    "* 1 estado $x_t$ * 4 pesos * 10 unidades = 40 pesos\n",
    "* 10 estados ocultos $h_{t-1}$ * 4 pesos * 10 unidades = 400 pesos\n",
    "* 1 bias * 4 pesos * 10 unidades = 40 pesos\n",
    "\n",
    "Total = 480 pesos\n",
    "\n",
    "Además, debemos agregar los 11 pesos de la capa `Dense`.\n",
    "\n",
    "Notamos que los bias ($b_f$) que comandan la memoria de largo plazo (*Forget gate*) se inicializan de manera opuesta, en 1, para conservar el valor inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Ajuste del modelo\n",
    "\n",
    "Entrenamos el modelo, es decir, ajustamos los pesos de acuerdo al esquema definido cuando fue compilado, por ejemplo `optimizer='Adam'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model training\n",
    "history = multivariate_lstm.fit(X_train, y_train, epochs=30, validation_split=0.1)\n",
    "\n",
    "# early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "# history = multivariate_lstm.fit(X_train, y_train, epochs=3000, validation_split=0.1, callbacks=[early_stopping_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Para tener una idea sobre la convergencia del moelo, mostramos las curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Luego que el modelo ha sido ajustado, es muy fácil obtener nuevas predicciones, como por ejemplo cuando le pasamos el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Plot with Dates on X-axis\n",
    "predicted_values = multivariate_lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensión de los datos de prueba ', X_test.shape)\n",
    "print('Dimensión de los datos de las predicciones ', predicted_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Vemos como de cada lote se obtiene un único valor por la configuración de la red como sequence-to-vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Evaluación de los resultados\n",
    "\n",
    "Ahora vamos a representar nuestro resultado. Construimos un `DataFrame` para almacenar los valores de `DEMANDA TOTAL` predecida y observada, y su fecha (que recuperamos de los datos originales). Este `DataFrame` nos facilitará el cálculo de distintas métricas que califican el grado de acuerdo de las predicciones del modelo con los valores registrados. Asimismo, representaremos en una figura ambas series de datos para tener una estimación visual del desempeño del modelo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Plot with Dates on X-axis\n",
    "LSTM_eval = pd.DataFrame({\n",
    "    'Predicted_DEMANDA': predicted_values[:, 0],\n",
    "    'Actual_DEMANDA': y_test[:, 0],\n",
    "})\n",
    "\n",
    "LSTM_eval.loc[:, 'Date'] = dataFrame['Fecha'][-len(y_test):].values\n",
    "# LSTM_eval.set_index('Date', inplace=True)\n",
    "LSTM_eval['Date'] = pd.to_datetime(LSTM_eval['Date'])\n",
    "LSTM_eval.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_eval.set_index('Date', inplace=True)\n",
    "LSTM_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una figura para representar las series de datos\n",
    "def FigPredActual(d, title):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    #  highlight the  forecast\n",
    "    # highlight_start = int(len(d) * 0.9)  \n",
    "    # highlight_end = len(d) - 1  # Adjusted to stay within bounds\n",
    "    # Plot the actual values\n",
    "    # plt.plot(d[['Actual_DEMANDA']][:highlight_start], label=['Actual_DEMANDA'])\n",
    "    plt.plot(d[['Actual_DEMANDA']], label=['Actual_DEMANDA'])\n",
    "    \n",
    "    # Plot predicted values with a dashed line\n",
    "    plt.plot(d[['Predicted_DEMANDA']], label=['Predicted_DEMANDA'], linestyle='--')\n",
    "    \n",
    "    # Highlight the forecasted portion with a different color\n",
    "    # plt.axvspan(d.index[highlight_start], d.index[highlight_end], facecolor='lightgreen', alpha=0.5, label='Forecast')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Values')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Trazamos ambas series de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "FigPredActual(LSTM_eval, 'Multivariate Time-Series forecasting using LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Definimos una función conveniente para calcular diferentes métrias que nos informan sobre el grado de acuerdo de las predicciones del modelo con las observaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def performance(d):\n",
    "    return {\n",
    "        'MSE': mean_squared_error(d['Actual_DEMANDA'].to_numpy(), d['Predicted_DEMANDA'].to_numpy()),\n",
    "        'MAE': mean_absolute_error(d['Actual_DEMANDA'].to_numpy(), d['Predicted_DEMANDA'].to_numpy()),\n",
    "        'R2': r2_score(d['Actual_DEMANDA'].to_numpy(), d['Predicted_DEMANDA'].to_numpy())\n",
    "    }\n",
    "\n",
    "performance(LSTM_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "También podemos usar el método `.evaluate()` de TF para recuperar las métricas usadas en el ajuste sobre el conjunto de Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_lstm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Reemplazar la capa LSTM por una más simple del tipo `keras.layers.SimpleRNN`. Analizar la cantidad de parámetros o pesos de calibración.\n",
    "\n",
    "2. Reponer nuevamente la capa del tipo `keras.layers.LSTM` pero en este caso definir 100 o 200 unidades. Evaluar sus resultados.\n",
    "\n",
    "3. Probar de entrenar nuevamente el mismo modelo con `.fit()` (sin redefinir). Confirmar que el ajuste avanza desde los valores de los pesos asignados para el último valor de `epoch`. Observar las nuevas curvas de aprendizaje. ¿Logra converger a mejores métricas?\n",
    "\n",
    "4. Proponer sobre el mismo modelo anterior un método de `callback` que pare el ajuste cuando se den condiciones de convergencia. Evaluar sus resultados. Aumentar el número asignado a `epochs` ya que esperamos la finalización por convergencia. \n",
    "\n",
    "5. Probar un modelo que agrega una 2da capa de celdas LSTM. Notar que para pasar los datos (el lote completo) a la 2da capa se debe definir `return_seguences=True` en la 1ra. Evaluar sus resultados.\n",
    "\n",
    "6. Elaborar un ciclo que reutilice el último valor pronosticado como entrada de un nuevo pronóstico. Esta es una estrategia que permite obtener pronósticos para más de un tiempo en adelante (aunque con error creciente). \n",
    "\n",
    "7. Desarrollar un modelo con 2 unidades en la última capa (densa) de manera de realizar pronósticos para los 2 pasos de tiempo siguientes. Modificar convenientemente la función `singleStepSampler()` para que devuelva 2 valores por lote para los conjuntos `y_train` e `y_test`. Esta es otra estrategia alternativa para el pronóstico de valores en tiempos futuros manteniendo un esquema sequence-to-vector. \n",
    "\n",
    "8. Probar un modelo sequence-to-sequence. Esto permite obtner prónosticos para varios pasos de tiempo por delante bajo una sola ejecución. Primero, definimos `return_sequences=True` en todas las capas LSTM. Notar que además de igualar la cantidad de unidades de la capa `Dense` al tamaño de la secuencia de salida agregamos `tf.keras.layers.TimeDistributed` para operar sobre cada corte de tiempo. Además, debemos editar la función `singleStepSampler()` para que devuelva tantos *targets* como la longitud de la secuencia de salida (`multiStepSampler()`). Evaluar sus resultados solo sobre un paso de tiempo adelante para comparar con las predicciones del modelo sequence-to-vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Generación de resultados de referencia\n",
    "\n",
    "Para valorar la calidad de las predicciones debemos comparar los resultados con valores de referencia o *baseline*. Estos se obtienen a partir de modelos sencillos y de fácil interpretación (*benchmark*). Se desea que los modelos más avanzados puedan superar las predicciones de los modelos simples. Esto otorga un criterio cunatitativo para la selección de modelos.\n",
    "\n",
    "### Baseline que repite el último valor\n",
    "\n",
    "Vamos a probar con un modelo Baseline que simplemente repite el útlimo valor de una semana atrás. Aquí tenemos en cuenta que la demanda dependerá fuertemente del día de la semana. Otra opción es repetir el último valor de la serie (se desecha el impacto de los fines de semana).\n",
    "\n",
    "### Aprovechando la Subclassing API para crear modelos dinámicos\n",
    "\n",
    "Algunas veces, nuestros modelos necesitarán del uso de lazos, condicionales u otros comportamientos dinámicos. Para estos casos, disponemos de la **Subclassing API** que aquí aprovecharemos para definir nuestro modelo Baseline (aunque es un ejemplo muy sencillo).\n",
    "\n",
    "La clase contiene un método `__init__()` que habitualmente se usa para declarar las capas involucradas. La arquitectura del modelo queda *oculta* dentro del método `__call_()`. Si bien tiene mayor flexibilidad, cuesta detectar errores y el modelo es menos transportable (con la función `save()`). \n",
    "\n",
    "Seguidamente, se compila, ajusta y evalúa de manera análoga a los modelos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs[:, -7, 0][...,np.newaxis]\n",
    "    return tf.gather(inputs, indices=tf.constant(self.label_index), axis=2)[:, -7, :]\n",
    "\n",
    "# Instantiate and evaluate this model:\n",
    "\n",
    "baseline = Baseline()\n",
    "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Forecast Plot with Dates on X-axis\n",
    "baseline_values = baseline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_eval = LSTM_eval.copy()\n",
    "Base_eval['Predicted_DEMANDA'] = baseline_values[:, 0]\n",
    "\n",
    "FigPredActual(Base_eval, 'Multivariate Time-Series forecasting using last week value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(Base_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "9. Recalcular las métricas anteriores para una referencia (*baseline*) que repite el valor observado en el día inmediatamente anterior.\n",
    "\n",
    "10. ecalcular las métricas anteriores para una referencia (baseline) que siempre predice el valor medio de la serie de entrenamiento. Interpretar la información que recuperamos de estas propuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### Baseline multipaso con una red densa\n",
    "\n",
    "Proponemos un nuevo benchmark basado en un *modelo lineal* que realiza sus predicciones accediendo a los valores anteriores. Es una versión simplificada de la celda LSTM ya que no realimenta sus salidas (no hay memoria, solo información de contexto). Es un modelo multipaso ya que sus entradas toman los valores instantaneos en pasos de tiempo anteriores. Por el contrario, recordamos que un modelo de un solo paso no tiene información de contexto. No puede *ver* cómo los valores de entrada van cambiando con el tiempo. En el modelo multipaso esperamos poder mejorar el entrenamiento y la predicción en el paso siguiente conociendo la historia de los valores que lo precedieron.\n",
    "\n",
    "Aquí usamos nuevamente un modelo secuencial. Esencialmente, convierte los recortes de la serie temporal de tamaño `BATCH_SIZE` en una tira de datos. La expectativa es encontrar pesos adecuados para las entradas vinculadas a valores en pasos anteriores y recuperar así una correcta serie de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Dense model\n",
    "univariate_dense = keras.Sequential([\n",
    "    keras.layers.Input((X_train.shape[1], 1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "univariate_dense.compile(loss = 'MeanSquaredError', metrics=['MAE'], optimizer='Adam')\n",
    "univariate_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training\n",
    "history = univariate_dense.fit(X_train, y_train, epochs=30, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast Plot with Dates on X-axis\n",
    "dense_values = univariate_dense.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense_eval = LSTM_eval.copy()\n",
    "Dense_eval['Predicted_DEMANDA'] = dense_values[:, 0]\n",
    "\n",
    "FigPredActual(Dense_eval, 'Multivariate Time-Series forecasting using Dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance(Dense_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "11. Recalcular las métricas anteriores para una referencia (baseline) que considere el siguiente modelo denso algo más potente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testear el siguiente modelo denso algo más potente\n",
    "univariate_dense2 = tf.keras.Sequential([\n",
    "    keras.layers.Input((X_train.shape[1], 1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "\n",
    "1. ¿Pueden los modelos que usan redes neuronales recurrentes superar a los predicciones más simples? ¿Cómo informaría los resultados hallados? Proponer un ejemplo.\n",
    "2. ¿Considera que la serie temporal de `DEMANDA TOTAL` puede ser predecida en base a la información de contexto pasada? ¿Se podría acotar la incertidumbre? En otras palabras, ¿por qué esperamos superar a los modelos benchmark? \n",
    "3. ¿Cuál es la importancia de los valores iniciales asignados de manera aleatoria a los pesos? ¿y si se continúa ajustando sin redefinir el modelo?\n",
    "4. ¿Puede tener impacto variar el tamaño `BATCH_SIZE`? Realice algunas pruebas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12-TF2.18",
   "language": "python",
   "name": "venv-tf2.18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
